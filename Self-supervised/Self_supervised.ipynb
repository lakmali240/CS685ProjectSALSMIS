{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJHiUb9AHUbm"
      },
      "source": [
        "# <font color=\"blue\">**CS685  : Project**</font> \n",
        "\n",
        "###Self-Supervised U-Net model implementation and weight saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ5NLhUyE6J3"
      },
      "outputs": [],
      "source": [
        "## mounting the google drive to load the data from directory\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFPc85P6hOdf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UQFqyjRhrX-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6do4FKFFOaM"
      },
      "source": [
        "#PART 1: Self Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq4C1jM9FHMs"
      },
      "source": [
        "##Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpu6h0-_ElCg"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "import scipy\n",
        "import imageio\n",
        "import string\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from skimage.transform import resize\n",
        "try:  # SciPy >= 0.19\n",
        "    from scipy.special import comb\n",
        "except ImportError:\n",
        "    from scipy.misc import comb\n",
        "\n",
        "def bernstein_poly(i, n, t):\n",
        "    \"\"\"\n",
        "     The Bernstein polynomial of n, i as a function of t\n",
        "    \"\"\"\n",
        "\n",
        "    return comb(n, i) * ( t**(n-i) ) * (1 - t)**i\n",
        "\n",
        "def bezier_curve(points, nTimes=1000):\n",
        "    \"\"\"\n",
        "       Given a set of control points, return the\n",
        "       bezier curve defined by the control points.\n",
        "\n",
        "       Control points should be a list of lists, or list of tuples\n",
        "       such as [ [1,1], \n",
        "                 [2,3], \n",
        "                 [4,5], ..[Xn, Yn] ]\n",
        "        nTimes is the number of time steps, defaults to 1000\n",
        "\n",
        "        See http://processingjs.nihongoresources.com/bezierinfo/\n",
        "    \"\"\"\n",
        "\n",
        "    nPoints = len(points)\n",
        "    xPoints = np.array([p[0] for p in points])\n",
        "    yPoints = np.array([p[1] for p in points])\n",
        "\n",
        "    t = np.linspace(0.0, 1.0, nTimes)\n",
        "\n",
        "    polynomial_array = np.array([ bernstein_poly(i, nPoints-1, t) for i in range(0, nPoints)   ])\n",
        "    \n",
        "    xvals = np.dot(xPoints, polynomial_array)\n",
        "    yvals = np.dot(yPoints, polynomial_array)\n",
        "\n",
        "    return xvals, yvals\n",
        "\n",
        "def data_augmentation(x, y, prob=0.5):\n",
        "    # augmentation by flipping\n",
        "    cnt = 3\n",
        "    while random.random() < prob and cnt > 0:\n",
        "        degree = random.choice([0, 1, 2])\n",
        "        x = np.flip(x, axis=degree)\n",
        "        y = np.flip(y, axis=degree)\n",
        "        cnt = cnt - 1\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def nonlinear_transformation(x, prob=0.5):\n",
        "    if random.random() >= prob:\n",
        "        return x\n",
        "    points = [[0, 0], [random.random(), random.random()], [random.random(), random.random()], [1, 1]]\n",
        "    xpoints = [p[0] for p in points]\n",
        "    ypoints = [p[1] for p in points]\n",
        "    xvals, yvals = bezier_curve(points, nTimes=100000)\n",
        "    if random.random() < 0.5:\n",
        "        # Half change to get flip\n",
        "        xvals = np.sort(xvals)\n",
        "    else:\n",
        "        xvals, yvals = np.sort(xvals), np.sort(yvals)\n",
        "    nonlinear_x = np.interp(x, xvals, yvals)\n",
        "    return nonlinear_x\n",
        "\n",
        "def local_pixel_shuffling(x, prob=0.5):\n",
        "    if random.random() >= prob:\n",
        "        return x\n",
        "    image_temp = copy.deepcopy(x)\n",
        "    orig_image = copy.deepcopy(x)\n",
        "    _, img_rows, img_cols = x.shape\n",
        "    num_block = 10000\n",
        "    for _ in range(num_block):\n",
        "        block_noise_size_x = random.randint(1, img_rows//10)\n",
        "        block_noise_size_y = random.randint(1, img_cols//10)\n",
        "        noise_x = random.randint(0, img_rows-block_noise_size_x)\n",
        "        noise_y = random.randint(0, img_cols-block_noise_size_y)\n",
        "        window = orig_image[0, noise_x:noise_x+block_noise_size_x, \n",
        "                               noise_y:noise_y+block_noise_size_y, \n",
        "                           ]\n",
        "        window = window.flatten()\n",
        "        np.random.shuffle(window)\n",
        "        window = window.reshape((block_noise_size_x, \n",
        "                                 block_noise_size_y))\n",
        "        image_temp[0, noise_x:noise_x+block_noise_size_x, \n",
        "                      noise_y:noise_y+block_noise_size_y] = window\n",
        "    local_shuffling_x = image_temp\n",
        "\n",
        "    return local_shuffling_x\n",
        "\n",
        "def image_in_painting(x):\n",
        "    _, img_rows, img_cols = x.shape\n",
        "    cnt = 5\n",
        "    while cnt > 0 and random.random() < 0.95:\n",
        "        block_noise_size_x = random.randint(img_rows//6, img_rows//3)\n",
        "        block_noise_size_y = random.randint(img_cols//6, img_cols//3)\n",
        "        noise_x = random.randint(3, img_rows-block_noise_size_x-3)\n",
        "        noise_y = random.randint(3, img_cols-block_noise_size_y-3)\n",
        "        x[:, \n",
        "          noise_x:noise_x+block_noise_size_x, \n",
        "          noise_y:noise_y+block_noise_size_y] = np.random.rand(block_noise_size_x, \n",
        "                                                               block_noise_size_y, ) * 1.0\n",
        "        cnt -= 1\n",
        "    return x\n",
        "\n",
        "def image_out_painting(x):\n",
        "    _, img_rows, img_cols = x.shape\n",
        "    image_temp = copy.deepcopy(x)\n",
        "    x = np.random.rand(x.shape[0], x.shape[1], x.shape[2], ) * 1.0\n",
        "    block_noise_size_x = img_rows - random.randint(3*img_rows//7, 4*img_rows//7)\n",
        "    block_noise_size_y = img_cols - random.randint(3*img_cols//7, 4*img_cols//7)\n",
        "    noise_x = random.randint(3, img_rows-block_noise_size_x-3)\n",
        "    noise_y = random.randint(3, img_cols-block_noise_size_y-3)\n",
        "    x[:, \n",
        "      noise_x:noise_x+block_noise_size_x, \n",
        "      noise_y:noise_y+block_noise_size_y] = image_temp[:, noise_x:noise_x+block_noise_size_x, \n",
        "                                                       noise_y:noise_y+block_noise_size_y]\n",
        "    cnt = 4\n",
        "    while cnt > 0 and random.random() < 0.95:\n",
        "        block_noise_size_x = img_rows - random.randint(3*img_rows//7, 4*img_rows//7)\n",
        "        block_noise_size_y = img_cols - random.randint(3*img_cols//7, 4*img_cols//7)\n",
        "        noise_x = random.randint(3, img_rows-block_noise_size_x-3)\n",
        "        noise_y = random.randint(3, img_cols-block_noise_size_y-3)\n",
        "        x[:, \n",
        "          noise_x:noise_x+block_noise_size_x, \n",
        "          noise_y:noise_y+block_noise_size_y] = image_temp[:, noise_x:noise_x+block_noise_size_x, \n",
        "                                                           noise_y:noise_y+block_noise_size_y]\n",
        "        cnt -= 1\n",
        "    return x\n",
        "                \n",
        "\n",
        "\n",
        "def generate_pair(img, batch_size, config, status=\"test\"):\n",
        "    img_rows, img_cols = img.shape[2], img.shape[3]\n",
        "    while True:\n",
        "        index = [i for i in range(img.shape[0])]\n",
        "        random.shuffle(index)\n",
        "        y = img[index[:batch_size]]\n",
        "        x = copy.deepcopy(y)\n",
        "        for n in range(batch_size):\n",
        "            \n",
        "            # Autoencoder\n",
        "            x[n] = copy.deepcopy(y[n])\n",
        "            \n",
        "            # Flip\n",
        "            x[n], y[n] = data_augmentation(x[n], y[n], config.flip_rate)\n",
        "\n",
        "            # Local Shuffle Pixel\n",
        "            x[n] = local_pixel_shuffling(x[n], prob=config.local_rate)\n",
        "            \n",
        "            # Apply non-Linear transformation with an assigned probability\n",
        "            x[n] = nonlinear_transformation(x[n], config.nonlinear_rate)\n",
        "            \n",
        "            # Inpainting & Outpainting\n",
        "            if random.random() < config.paint_rate:\n",
        "                if random.random() < config.inpaint_rate:\n",
        "                    # Inpainting\n",
        "                    x[n] = image_in_painting(x[n])\n",
        "                else:\n",
        "                    # Outpainting\n",
        "                    x[n] = image_out_painting(x[n])\n",
        "\n",
        "        # Save sample images module\n",
        "        if config.save_samples is not None and status == \"train\" and random.random() < 0.01:\n",
        "            n_sample = random.choice( [i for i in range(config.batch_size)] )\n",
        "            final_sample = np.concatenate((x[n_sample,0,:,:], y[n_sample,0,:,:]), axis=1)\n",
        "            final_sample = final_sample * 255.0\n",
        "            final_sample = final_sample.astype(np.uint8)\n",
        "            file_name = ''.join([random.choice(string.ascii_letters + string.digits) for n in range(10)])+'.'+config.save_samples\n",
        "            imageio.imwrite(os.path.join(config.sample_path, config.exp_name, file_name), final_sample)\n",
        "\n",
        "        yield (x, y)\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xEowzROFBz2"
      },
      "source": [
        "#UNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7onEP8aE83G"
      },
      "outputs": [],
      "source": [
        "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
        "\n",
        "\"\"\" Parts of the U-Net model \"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.conv(x))\n",
        "\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "    \n",
        "        #per_out=[]\n",
        "        \n",
        "        x1 = self.inc(x)\n",
        "        #per_out.append(x1) # conv1\n",
        "        \n",
        "        x2 = self.down1(x1)\n",
        "        #per_out.append(x2) # down1\n",
        "        \n",
        "        x3 = self.down2(x2)\n",
        "        #per_out.append(x3) # down2\n",
        "        \n",
        "        x4 = self.down3(x3)\n",
        "        #per_out.append(x4) # down3\n",
        "        \n",
        "        x5 = self.down4(x4)\n",
        "        #per_out.append(x5) # down4\n",
        "        \n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        \n",
        "        return logits\n",
        "\n",
        "    \n",
        "class UNet_hidden(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet_hidden, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "    \n",
        "        #per_out=[]\n",
        "        \n",
        "        x1 = self.inc(x)\n",
        "        #per_out.append(x1) # conv1\n",
        "        \n",
        "        x2 = self.down1(x1)\n",
        "        #per_out.append(x2) # down1\n",
        "        \n",
        "        x3 = self.down2(x2)\n",
        "        #per_out.append(x3) # down2\n",
        "        \n",
        "        x4 = self.down3(x3)\n",
        "        #per_out.append(x4) # down3\n",
        "        \n",
        "        x5 = self.down4(x4)\n",
        "        #per_out.append(x5) # down4\n",
        "        \n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        \n",
        "        return logits, x5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HukLOnkkiMeH"
      },
      "source": [
        "##Swin_UNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNyFqbI4zoFk"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # from torchvision.models.utils import load_state_dict_from_url\n",
        "\n",
        "# # Swin Transformer Encoder Block\n",
        "# class SwinTransformerEncoderBlock(nn.Module):\n",
        "#     def __init__(self, embed_dim, num_heads, window_size, shift_size, mlp_ratio=4.0):\n",
        "#         super().__init__()\n",
        "#         self.norm1 = nn.LayerNorm(embed_dim)\n",
        "#         self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "#         self.norm2 = nn.LayerNorm(embed_dim)\n",
        "#         self.mlp = nn.Sequential(\n",
        "#             nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),\n",
        "#             nn.GELU(),\n",
        "#             nn.Linear(int(embed_dim * mlp_ratio), embed_dim),\n",
        "#         )\n",
        "\n",
        "#         # Window partitioning and shifting\n",
        "#         self.window_size = window_size\n",
        "#         self.shift_size = shift_size\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Apply layer normalization\n",
        "#         x = self.norm1(x)\n",
        "\n",
        "#         # Apply self-attention\n",
        "#         x = x.permute(2, 0, 1)\n",
        "#         x, _ = self.attn(x, x, x)\n",
        "#         x = x.permute(1, 2, 0)\n",
        "\n",
        "#         # Apply residual connection and layer normalization\n",
        "#         x = x + x.permute(0, 2, 1)\n",
        "#         x = self.norm2(x)\n",
        "\n",
        "#         # Apply MLP\n",
        "#         y = self.mlp(x)\n",
        "\n",
        "#         # Partition into non-overlapping windows and shift\n",
        "#         B, N, C = y.shape\n",
        "#         h = self.window_size\n",
        "#         w = N // h\n",
        "#         y = y.view(B, h, w, C)\n",
        "#         y = y.permute(0, 3, 1, 2)\n",
        "#         y = torch.nn.functional.pad(y, (0, 0, 0, 0, self.shift_size // 2, self.shift_size // 2), mode=\"constant\")\n",
        "#         y = y.reshape(B, C, h * (w + 2 * (self.shift_size // 2)))\n",
        "#         y = y.permute(0, 2, 1)\n",
        "\n",
        "#         # Apply residual connection\n",
        "#         y = y + x\n",
        "\n",
        "#         return y\n",
        "\n",
        "# # Swin UNet Model\n",
        "# class SwinUNet(nn.Module):\n",
        "#     def __init__(self, input_channels, num_classes):\n",
        "#         super().__init__()\n",
        "\n",
        "#         # Swin Transformer Encoder Blocks\n",
        "#         self.enc1 = SwinTransformerEncoderBlock(embed_dim=64, num_heads=2, window_size=7, shift_size=0)\n",
        "#         self.enc2 = SwinTransformerEncoderBlock(embed_dim=128, num_heads=4, window_size=7, shift_size=0)\n",
        "#         self.enc3 = SwinTransformerEncoderBlock(embed_dim=256, num_heads=8, window_size=7, shift_size=0)\n",
        "#         self.enc4 = SwinTransformerEncoderBlock(embed_dim=512, num_heads=16, window_size=7, shift_size=0)\n",
        "\n",
        "#         # Swin Transformer Decoder Blocks\n",
        "#         self.dec1 = SwinTransformerEncoderBlock(embed_dim=256, num_heads=8, window_size=7, shift_size=0)\n",
        "#         self.dec2 = SwinTransformerEncoderBlock(embed_dim=128, num_heads=4, window_size=7, shift_size=0)\n",
        "#         self.dec3 = SwinTransformerEncoderBlock(embed_dim=64, num_heads=2, window_size=7, shift_size=0)\n",
        "\n",
        "#         # Final convolutional layer for segmentation output\n",
        "#         self.final_conv = nn.Conv2d(96, num_classes, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Encoder\n",
        "#         x1 = self.enc1(x)\n",
        "#         x2 = self.enc2(x1)\n",
        "#         x3 = self.enc3(x2)\n",
        "#         x4 = self.enc4(x3)\n",
        "\n",
        "#         # Decoder\n",
        "#         y1 = self.dec1(x4) + nn.functional.interpolate(x4, scale_factor=2, mode=\"nearest\")\n",
        "#         y2 = self.dec2(y1) + nn.functional.interpolate(y1, scale_factor=2, mode=\"nearest\")\n",
        "#         y3 = self.dec3(y2) + nn.functional.interpolate(y2, scale_factor=2, mode=\"nearest\")\n",
        "\n",
        "#         # Output\n",
        "#         y = self.final_conv(y3)\n",
        "#         return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIjhLRQpiPZQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# from torchvision.models.utils import load_state_dict_from_url\n",
        "\n",
        "# Swin Transformer Encoder Block\n",
        "class SwinTransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, window_size, shift_size, mlp_ratio=4.0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(embed_dim,(256, 256))\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim,(256, 256))\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(int(embed_dim * mlp_ratio), embed_dim),\n",
        "        )\n",
        "\n",
        "        # Window partitioning and shifting\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply layer normalization\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Apply self-attention\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        B, H, W, C = x.shape\n",
        "        x = x.reshape(B * H * W, C, 1)\n",
        "        x, _ = self.attn(x, x, x)\n",
        "        x = x.reshape(B, H, W, C)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Apply residual connection and layer normalization\n",
        "        x = x + x.permute(0, 2, 3, 1)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        # Apply MLP\n",
        "        y = self.mlp(x)\n",
        "\n",
        "        # Partition into non-overlapping windows and shift\n",
        "        B, N, C = y.shape\n",
        "        h = self.window_size\n",
        "        w = N // h\n",
        "        y = y.view(B, h, w, C)\n",
        "        y = y.permute(0, 3, 1, 2)\n",
        "        y = torch.nn.functional.pad(y, (0, 0, 0, 0, self.shift_size // 2, self.shift_size // 2), mode=\"constant\")\n",
        "        y = y.reshape(B, C, h * (w + 2 * (self.shift_size // 2)))\n",
        "        y = y.permute(0, 2, 1)\n",
        "\n",
        "        # Apply residual connection\n",
        "        y = y + x\n",
        "\n",
        "        return y\n",
        "\n",
        "# Swin UNet Model\n",
        "class SwinUNet(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Swin Transformer Encoder Blocks\n",
        "        self.enc1 = SwinTransformerEncoderBlock(embed_dim=64, num_heads=2, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.enc2 = SwinTransformerEncoderBlock(embed_dim=128, num_heads=4, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.enc3 = SwinTransformerEncoderBlock(embed_dim=256, num_heads=8, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.enc4 = SwinTransformerEncoderBlock(embed_dim=512, num_heads=16, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "\n",
        "        # Swin Transformer Decoder Blocks\n",
        "        self.dec1 = SwinTransformerEncoderBlock(embed_dim=256, num_heads=8, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.dec2 = SwinTransformerEncoderBlock(embed_dim=128, num_heads=4, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.dec3 = SwinTransformerEncoderBlock(embed_dim=64, num_heads=2, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "\n",
        "        # Final convolutional layer for segmentation output\n",
        "        self.final_conv = nn.Conv2d(96, num_classes, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        # Modify the input channel of the first convolutional layer\n",
        "        self.conv_input = nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.conv_input(x)\n",
        "        x1 = self.enc1(x)\n",
        "        x2 = self.enc2(x1)\n",
        "        x3 = self.enc3(x2)\n",
        "        x4 = self.enc4(x3)\n",
        "\n",
        "        # Decoder\n",
        "        y1 = self.dec1(x4) + nn.functional.interpolate(x4, scale_factor=2, mode=\"nearest\")\n",
        "        y2 = self.dec2(y1) + nn.functional.interpolate(y1, scale_factor=2, mode=\"nearest\")\n",
        "        y3 = self.dec3(y2) + nn.functional.interpolate(y2, scale_factor=2, mode=\"nearest\")\n",
        "\n",
        "        # Output\n",
        "        y = self.final_conv(y3)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chYBpoNxFQz1"
      },
      "source": [
        "##Config_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhkePFepFU5_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "class models_genesis_config:\n",
        "    model = \"Unet2D\"\n",
        "    suffix = \"genesis_chest_ct\"\n",
        "    exp_name = model + \"-\" + suffix\n",
        "    \n",
        "    # data\n",
        "    data = \"/mnt/dataset/shared/zongwei/LUNA16/Self_Learning_Cubes\" # not use\n",
        "    scale = 32\n",
        "    input_rows = 256\n",
        "    input_cols = 256\n",
        "    input_deps = 1\n",
        "    nb_class = 1\n",
        "\n",
        "    # image deformation\n",
        "    nonlinear_rate = 0.9\n",
        "    paint_rate = 0.9\n",
        "    outpaint_rate = 0.8\n",
        "    inpaint_rate = 1.0 - outpaint_rate\n",
        "    local_rate = 0.5\n",
        "    flip_rate = 0.4\n",
        "    \n",
        "    # logs\n",
        "    # model_dir = \"../SSLModel/Reuslts/pretrained_weights\"\n",
        "    model_dir = \"/content/drive/MyDrive/Spring_research_2023/SSLModel/Reuslts/pretrained_weights\"\n",
        "    timenow = datetime.strftime(datetime.now(pytz.timezone('Asia/Singapore')), '%Y-%m-%d_%H-%M-%S')\n",
        "    model_path = os.path.join(model_dir,timenow)\n",
        "    print('Model path: ',model_path)\n",
        "    if not os.path.exists(model_path):\n",
        "        os.makedirs(model_path)\n",
        "        \n",
        "    logs_path = os.path.join(model_path, \"Logs\")\n",
        "    print('log path: ',logs_path)\n",
        "    if not os.path.exists(logs_path):\n",
        "        os.makedirs(logs_path)\n",
        "        \n",
        "    shotdir = os.path.join(model_path, 'snapshot')\n",
        "    print('snapshot path: ',shotdir)\n",
        "    if not os.path.exists(shotdir):\n",
        "        os.makedirs(shotdir)\n",
        "    \n",
        "    # model pre-training\n",
        "    verbose = 1\n",
        "    weights = os.path.join(model_path,'ISIC_Unsup.pt')\n",
        "    batch_size = 1\n",
        "    optimizer = \"sgd\"\n",
        "    workers = 10\n",
        "    max_queue_size = workers * 4\n",
        "    save_samples = \"png\"\n",
        "    nb_epoch = 10000\n",
        "    patience = 100\n",
        "    lr = 0.01\n",
        "    \n",
        "    def display(self):\n",
        "        \"\"\"Display Configuration values.\"\"\"\n",
        "        print(\"\\nConfigurations:\")\n",
        "        for a in dir(self):\n",
        "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
        "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osDqssExFcnP"
      },
      "source": [
        "##Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ2VNWYaFfCN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import imgaug.augmenters as iaa\n",
        "#from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(1)\n",
        "\n",
        "\n",
        "def Dataset_Loader(path, img_size):\n",
        "    print('\\nLoading dataset...\\n')\n",
        "    read_imgs = np.load(path)\n",
        "    rows = img_size[0]\n",
        "    cols = img_size[1]\n",
        "    \n",
        "    images = np.ndarray((read_imgs.shape[0], read_imgs.shape[-1], rows, cols), dtype=float)\n",
        "    for i in range(read_imgs.shape[0]):\n",
        "        img = cv2.resize(read_imgs[i, 0], (cols, rows), interpolation=cv2.INTER_CUBIC)\n",
        "        images[i, 0, :, :] = img/255.\n",
        "    return images\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_path_train = '/content/drive/MyDrive/Spring_research_2023/data/GrayData'\n",
        "    trainpath = data_path_train + '/imgs_train.npy'\n",
        "    \n",
        "    dataset = Dataset_Loader(trainpath,[256,256])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lflGrDgUE9Vt"
      },
      "source": [
        "##Pre-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rb16lbVEs-Y"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "# ref https://github.com/MrGiovanni/ModelsGenesis\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import sys\n",
        "# from utils import *\n",
        "# from unet_model2 import UNet\n",
        "# from config_cluster import models_genesis_config\n",
        "# from data_load import Dataset_Loader\n",
        "import logging\n",
        "import os\n",
        "\n",
        "print(\"torch = {}\".format(torch.__version__))\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
        "\n",
        "conf = models_genesis_config()\n",
        "conf.display()\n",
        "img_size = [256,256]\n",
        "\n",
        "# data load\n",
        "\n",
        "'''\n",
        "in unsupervised learning,\n",
        "train set = 1600\n",
        "validation set = 400\n",
        "test 1: fix the train set for the first 1600\n",
        "pixel value scale :[0,1]\n",
        "resize: 16*N  = 256\n",
        "'''\n",
        "train_path = '/content/drive/MyDrive/Spring_research_2023/data/GrayData/imgs_train.npy'\n",
        "train_set = Dataset_Loader(train_path,img_size)\n",
        "\n",
        "train_num =  1600 # Lakmali: 1600\n",
        "valid_num =  400 # Lakmali: 400\n",
        "total_num = len(train_set)\n",
        "x_train = train_set[0:train_num]\n",
        "x_valid = train_set[train_num:train_num+valid_num]\n",
        "\n",
        "logging.basicConfig(filename=conf.shotdir+\"/\"+\"snapshot.txt\", level=logging.INFO,\n",
        "                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
        "logging.info(str(conf))\n",
        "\n",
        "print(\"x_train: {} | {:.2f} ~ {:.2f}\".format(x_train.shape, np.min(x_train), np.max(x_train)))\n",
        "print(\"x_valid: {} | {:.2f} ~ {:.2f}\".format(x_valid.shape, np.min(x_valid), np.max(x_valid)))\n",
        "\n",
        "training_generator = generate_pair(x_train,conf.batch_size, conf)\n",
        "validation_generator = generate_pair(x_valid,conf.batch_size, conf)\n",
        "\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Lakmali: model = UNet(n_channels=1, n_classes=conf.nb_class).cuda()\n",
        "model = UNet(n_channels=1, n_classes=conf.nb_class).cuda()\n",
        "#model = SwinUNet(input_channels=1, num_classes=conf.nb_class)\n",
        "model.to(device)\n",
        "\n",
        "print(\"Total CUDA devices: \", torch.cuda.device_count())\n",
        "\n",
        "summary(model, (1,conf.input_rows,conf.input_cols), batch_size=-1)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "if conf.optimizer == \"sgd\":\n",
        "\toptimizer = torch.optim.SGD(model.parameters(), conf.lr, momentum=0.9, weight_decay=0.0, nesterov=False)\n",
        "elif conf.optimizer == \"adam\":\n",
        "\toptimizer = torch.optim.Adam(model.parameters(), conf.lr)\n",
        "else:\n",
        "\traise\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(conf.patience * 0.8), gamma=0.5)\n",
        "\n",
        "# to track the training loss as the model trains\n",
        "train_losses = []\n",
        "# to track the validation loss as the model trains\n",
        "valid_losses = []\n",
        "# to track the average training loss per epoch as the model trains\n",
        "avg_train_losses = []\n",
        "# to track the average validation loss per epoch as the model trains\n",
        "avg_valid_losses = []\n",
        "#best_loss = 100000\n",
        "best_loss = 0.03 # Lakmali: 0.02\n",
        "intial_epoch =0\n",
        "num_epoch_no_improvement = 0\n",
        "sys.stdout.flush()\n",
        "\n",
        "print(conf.weights) # Lakali:\n",
        "\n",
        "'''\n",
        "# Lakmali:\n",
        "file_path = conf.weights\n",
        "\n",
        "# Save the model weights as a .pt file\n",
        "torch.save(model.state_dict(), file_path)\n",
        "\n",
        "\n",
        "if conf.weights != None:    \n",
        "\tcheckpoint=torch.load(conf.weights)\n",
        "\tmodel.load_state_dict(checkpoint['state_dict'])\n",
        "\toptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\tintial_epoch=checkpoint['epoch']\n",
        "\tprint(\"Loading weights from \",conf.weights)\n",
        "sys.stdout.flush()\n",
        "'''\n",
        "\n",
        "for epoch in range(intial_epoch,conf.nb_epoch):\n",
        "    scheduler.step(epoch)\n",
        "    model.train()\n",
        "    for iteration in range(100): # Lakmali:  for iteration in range(int(x_train.shape[0]//conf.batch_size)):\n",
        "        image, gt = next(training_generator)\n",
        "        gt = np.repeat(gt,conf.nb_class,axis=1)\n",
        "        image,gt = torch.from_numpy(image).float().to(device), torch.from_numpy(gt).float().to(device)\n",
        "        pred=model(image)\n",
        "        pred=torch.sigmoid(pred)\n",
        "        \n",
        "        loss = criterion(pred,gt)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(round(loss.item(), 2))\n",
        "        if (iteration + 1) % 5 ==0:\n",
        "            print('Epoch [{}/{}], iteration {}, Loss: {:.6f}'.format(epoch + 1, conf.nb_epoch, iteration + 1, np.average(train_losses)))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        print(\"validating....\")\n",
        "        for i in range(int(x_valid.shape[0]//conf.batch_size)):\n",
        "            x,y = next(validation_generator)\n",
        "            y = np.repeat(y,conf.nb_class,axis=1)\n",
        "            image,gt = torch.from_numpy(x).float(), torch.from_numpy(y).float()\n",
        "            image=image.to(device)\n",
        "            gt=gt.to(device)\n",
        "            pred=model(image)\n",
        "            pred=torch.sigmoid(pred)\n",
        "            loss = criterion(pred,gt)\n",
        "            valid_losses.append(loss.item())\n",
        "    \n",
        "    #logging\n",
        "    train_loss=np.average(train_losses)\n",
        "    valid_loss=np.average(valid_losses)\n",
        "    avg_train_losses.append(train_loss)\n",
        "    avg_valid_losses.append(valid_loss)\n",
        "    print(\"Epoch {}, validation loss is {:.4f}, training loss is {:.4f}\".format(epoch+1,valid_loss,train_loss))\n",
        "    train_losses=[]\n",
        "    valid_losses=[]\n",
        "    if valid_loss < best_loss:\n",
        "        print(\"Validation loss decreases from {:.4f} to {:.4f}\".format(best_loss, valid_loss))\n",
        "        best_loss = valid_loss\n",
        "        num_epoch_no_improvement = 0\n",
        "        #save model\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'state_dict' : model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "        },os.path.join(conf.model_path, \"ISIC_Unsup.pt\"))\n",
        "        print(\"Saving model \",os.path.join(conf.model_path, \"ISIC_Unsup.pt\"))\n",
        "    else:\n",
        "        print(\"Validation loss does not decrease from {:.4f}, num_epoch_no_improvement {}\".format(best_loss,num_epoch_no_improvement))\n",
        "        num_epoch_no_improvement += 1\n",
        "    if num_epoch_no_improvement == conf.patience:\n",
        "        print(\"Early Stopping\")\n",
        "        break\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8Z9qceypzrJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
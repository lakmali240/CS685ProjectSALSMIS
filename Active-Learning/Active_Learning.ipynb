{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJHiUb9AHUbm"
      },
      "source": [
        "# <font color=\"blue\">**CS685  : Project**</font> \n",
        "\n",
        "###Active Learning for optimal sample selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ5NLhUyE6J3"
      },
      "outputs": [],
      "source": [
        "## mounting the google drive to load the data from directory\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFPc85P6hOdf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UQFqyjRhrX-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq4C1jM9FHMs"
      },
      "source": [
        "##Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpu6h0-_ElCg"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "import scipy\n",
        "import imageio\n",
        "import string\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from skimage.transform import resize\n",
        "try:  # SciPy >= 0.19\n",
        "    from scipy.special import comb\n",
        "except ImportError:\n",
        "    from scipy.misc import comb\n",
        "\n",
        "def bernstein_poly(i, n, t):\n",
        "    \"\"\"\n",
        "     The Bernstein polynomial of n, i as a function of t\n",
        "    \"\"\"\n",
        "\n",
        "    return comb(n, i) * ( t**(n-i) ) * (1 - t)**i\n",
        "\n",
        "def bezier_curve(points, nTimes=1000):\n",
        "    \"\"\"\n",
        "       Given a set of control points, return the\n",
        "       bezier curve defined by the control points.\n",
        "\n",
        "       Control points should be a list of lists, or list of tuples\n",
        "       such as [ [1,1], \n",
        "                 [2,3], \n",
        "                 [4,5], ..[Xn, Yn] ]\n",
        "        nTimes is the number of time steps, defaults to 1000\n",
        "\n",
        "        See http://processingjs.nihongoresources.com/bezierinfo/\n",
        "    \"\"\"\n",
        "\n",
        "    nPoints = len(points)\n",
        "    xPoints = np.array([p[0] for p in points])\n",
        "    yPoints = np.array([p[1] for p in points])\n",
        "\n",
        "    t = np.linspace(0.0, 1.0, nTimes)\n",
        "\n",
        "    polynomial_array = np.array([ bernstein_poly(i, nPoints-1, t) for i in range(0, nPoints)   ])\n",
        "    \n",
        "    xvals = np.dot(xPoints, polynomial_array)\n",
        "    yvals = np.dot(yPoints, polynomial_array)\n",
        "\n",
        "    return xvals, yvals\n",
        "\n",
        "def data_augmentation(x, y, prob=0.5):\n",
        "    # augmentation by flipping\n",
        "    cnt = 3\n",
        "    while random.random() < prob and cnt > 0:\n",
        "        degree = random.choice([0, 1, 2])\n",
        "        x = np.flip(x, axis=degree)\n",
        "        y = np.flip(y, axis=degree)\n",
        "        cnt = cnt - 1\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def nonlinear_transformation(x, prob=0.5):\n",
        "    if random.random() >= prob:\n",
        "        return x\n",
        "    points = [[0, 0], [random.random(), random.random()], [random.random(), random.random()], [1, 1]]\n",
        "    xpoints = [p[0] for p in points]\n",
        "    ypoints = [p[1] for p in points]\n",
        "    xvals, yvals = bezier_curve(points, nTimes=100000)\n",
        "    if random.random() < 0.5:\n",
        "        # Half change to get flip\n",
        "        xvals = np.sort(xvals)\n",
        "    else:\n",
        "        xvals, yvals = np.sort(xvals), np.sort(yvals)\n",
        "    nonlinear_x = np.interp(x, xvals, yvals)\n",
        "    return nonlinear_x\n",
        "\n",
        "def local_pixel_shuffling(x, prob=0.5):\n",
        "    if random.random() >= prob:\n",
        "        return x\n",
        "    image_temp = copy.deepcopy(x)\n",
        "    orig_image = copy.deepcopy(x)\n",
        "    _, img_rows, img_cols = x.shape\n",
        "    num_block = 10000\n",
        "    for _ in range(num_block):\n",
        "        block_noise_size_x = random.randint(1, img_rows//10)\n",
        "        block_noise_size_y = random.randint(1, img_cols//10)\n",
        "        noise_x = random.randint(0, img_rows-block_noise_size_x)\n",
        "        noise_y = random.randint(0, img_cols-block_noise_size_y)\n",
        "        window = orig_image[0, noise_x:noise_x+block_noise_size_x, \n",
        "                               noise_y:noise_y+block_noise_size_y, \n",
        "                           ]\n",
        "        window = window.flatten()\n",
        "        np.random.shuffle(window)\n",
        "        window = window.reshape((block_noise_size_x, \n",
        "                                 block_noise_size_y))\n",
        "        image_temp[0, noise_x:noise_x+block_noise_size_x, \n",
        "                      noise_y:noise_y+block_noise_size_y] = window\n",
        "    local_shuffling_x = image_temp\n",
        "\n",
        "    return local_shuffling_x\n",
        "\n",
        "def image_in_painting(x):\n",
        "    _, img_rows, img_cols = x.shape\n",
        "    cnt = 5\n",
        "    while cnt > 0 and random.random() < 0.95:\n",
        "        block_noise_size_x = random.randint(img_rows//6, img_rows//3)\n",
        "        block_noise_size_y = random.randint(img_cols//6, img_cols//3)\n",
        "        noise_x = random.randint(3, img_rows-block_noise_size_x-3)\n",
        "        noise_y = random.randint(3, img_cols-block_noise_size_y-3)\n",
        "        x[:, \n",
        "          noise_x:noise_x+block_noise_size_x, \n",
        "          noise_y:noise_y+block_noise_size_y] = np.random.rand(block_noise_size_x, \n",
        "                                                               block_noise_size_y, ) * 1.0\n",
        "        cnt -= 1\n",
        "    return x\n",
        "\n",
        "def image_out_painting(x):\n",
        "    _, img_rows, img_cols = x.shape\n",
        "    image_temp = copy.deepcopy(x)\n",
        "    x = np.random.rand(x.shape[0], x.shape[1], x.shape[2], ) * 1.0\n",
        "    block_noise_size_x = img_rows - random.randint(3*img_rows//7, 4*img_rows//7)\n",
        "    block_noise_size_y = img_cols - random.randint(3*img_cols//7, 4*img_cols//7)\n",
        "    noise_x = random.randint(3, img_rows-block_noise_size_x-3)\n",
        "    noise_y = random.randint(3, img_cols-block_noise_size_y-3)\n",
        "    x[:, \n",
        "      noise_x:noise_x+block_noise_size_x, \n",
        "      noise_y:noise_y+block_noise_size_y] = image_temp[:, noise_x:noise_x+block_noise_size_x, \n",
        "                                                       noise_y:noise_y+block_noise_size_y]\n",
        "    cnt = 4\n",
        "    while cnt > 0 and random.random() < 0.95:\n",
        "        block_noise_size_x = img_rows - random.randint(3*img_rows//7, 4*img_rows//7)\n",
        "        block_noise_size_y = img_cols - random.randint(3*img_cols//7, 4*img_cols//7)\n",
        "        noise_x = random.randint(3, img_rows-block_noise_size_x-3)\n",
        "        noise_y = random.randint(3, img_cols-block_noise_size_y-3)\n",
        "        x[:, \n",
        "          noise_x:noise_x+block_noise_size_x, \n",
        "          noise_y:noise_y+block_noise_size_y] = image_temp[:, noise_x:noise_x+block_noise_size_x, \n",
        "                                                           noise_y:noise_y+block_noise_size_y]\n",
        "        cnt -= 1\n",
        "    return x\n",
        "                \n",
        "\n",
        "\n",
        "def generate_pair(img, batch_size, config, status=\"test\"):\n",
        "    img_rows, img_cols = img.shape[2], img.shape[3]\n",
        "    while True:\n",
        "        index = [i for i in range(img.shape[0])]\n",
        "        random.shuffle(index)\n",
        "        y = img[index[:batch_size]]\n",
        "        x = copy.deepcopy(y)\n",
        "        for n in range(batch_size):\n",
        "            \n",
        "            # Autoencoder\n",
        "            x[n] = copy.deepcopy(y[n])\n",
        "            \n",
        "            # Flip\n",
        "            x[n], y[n] = data_augmentation(x[n], y[n], config.flip_rate)\n",
        "\n",
        "            # Local Shuffle Pixel\n",
        "            x[n] = local_pixel_shuffling(x[n], prob=config.local_rate)\n",
        "            \n",
        "            # Apply non-Linear transformation with an assigned probability\n",
        "            x[n] = nonlinear_transformation(x[n], config.nonlinear_rate)\n",
        "            \n",
        "            # Inpainting & Outpainting\n",
        "            if random.random() < config.paint_rate:\n",
        "                if random.random() < config.inpaint_rate:\n",
        "                    # Inpainting\n",
        "                    x[n] = image_in_painting(x[n])\n",
        "                else:\n",
        "                    # Outpainting\n",
        "                    x[n] = image_out_painting(x[n])\n",
        "\n",
        "        # Save sample images module\n",
        "        if config.save_samples is not None and status == \"train\" and random.random() < 0.01:\n",
        "            n_sample = random.choice( [i for i in range(config.batch_size)] )\n",
        "            final_sample = np.concatenate((x[n_sample,0,:,:], y[n_sample,0,:,:]), axis=1)\n",
        "            final_sample = final_sample * 255.0\n",
        "            final_sample = final_sample.astype(np.uint8)\n",
        "            file_name = ''.join([random.choice(string.ascii_letters + string.digits) for n in range(10)])+'.'+config.save_samples\n",
        "            imageio.imwrite(os.path.join(config.sample_path, config.exp_name, file_name), final_sample)\n",
        "\n",
        "        yield (x, y)\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xEowzROFBz2"
      },
      "source": [
        "#UNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7onEP8aE83G"
      },
      "outputs": [],
      "source": [
        "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
        "\n",
        "\"\"\" Parts of the U-Net model \"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.conv(x))\n",
        "\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "    \n",
        "        #per_out=[]\n",
        "        \n",
        "        x1 = self.inc(x)\n",
        "        #per_out.append(x1) # conv1\n",
        "        \n",
        "        x2 = self.down1(x1)\n",
        "        #per_out.append(x2) # down1\n",
        "        \n",
        "        x3 = self.down2(x2)\n",
        "        #per_out.append(x3) # down2\n",
        "        \n",
        "        x4 = self.down3(x3)\n",
        "        #per_out.append(x4) # down3\n",
        "        \n",
        "        x5 = self.down4(x4)\n",
        "        #per_out.append(x5) # down4\n",
        "        \n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        \n",
        "        return logits\n",
        "\n",
        "    \n",
        "class UNet_hidden(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet_hidden, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "    \n",
        "        #per_out=[]\n",
        "        \n",
        "        x1 = self.inc(x)\n",
        "        #per_out.append(x1) # conv1\n",
        "        \n",
        "        x2 = self.down1(x1)\n",
        "        #per_out.append(x2) # down1\n",
        "        \n",
        "        x3 = self.down2(x2)\n",
        "        #per_out.append(x3) # down2\n",
        "        \n",
        "        x4 = self.down3(x3)\n",
        "        #per_out.append(x4) # down3\n",
        "        \n",
        "        x5 = self.down4(x4)\n",
        "        #per_out.append(x5) # down4\n",
        "        \n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        \n",
        "        return logits, x5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HukLOnkkiMeH"
      },
      "source": [
        "##Swin_UNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNyFqbI4zoFk"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # from torchvision.models.utils import load_state_dict_from_url\n",
        "\n",
        "# # Swin Transformer Encoder Block\n",
        "# class SwinTransformerEncoderBlock(nn.Module):\n",
        "#     def __init__(self, embed_dim, num_heads, window_size, shift_size, mlp_ratio=4.0):\n",
        "#         super().__init__()\n",
        "#         self.norm1 = nn.LayerNorm(embed_dim)\n",
        "#         self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "#         self.norm2 = nn.LayerNorm(embed_dim)\n",
        "#         self.mlp = nn.Sequential(\n",
        "#             nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),\n",
        "#             nn.GELU(),\n",
        "#             nn.Linear(int(embed_dim * mlp_ratio), embed_dim),\n",
        "#         )\n",
        "\n",
        "#         # Window partitioning and shifting\n",
        "#         self.window_size = window_size\n",
        "#         self.shift_size = shift_size\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Apply layer normalization\n",
        "#         x = self.norm1(x)\n",
        "\n",
        "#         # Apply self-attention\n",
        "#         x = x.permute(2, 0, 1)\n",
        "#         x, _ = self.attn(x, x, x)\n",
        "#         x = x.permute(1, 2, 0)\n",
        "\n",
        "#         # Apply residual connection and layer normalization\n",
        "#         x = x + x.permute(0, 2, 1)\n",
        "#         x = self.norm2(x)\n",
        "\n",
        "#         # Apply MLP\n",
        "#         y = self.mlp(x)\n",
        "\n",
        "#         # Partition into non-overlapping windows and shift\n",
        "#         B, N, C = y.shape\n",
        "#         h = self.window_size\n",
        "#         w = N // h\n",
        "#         y = y.view(B, h, w, C)\n",
        "#         y = y.permute(0, 3, 1, 2)\n",
        "#         y = torch.nn.functional.pad(y, (0, 0, 0, 0, self.shift_size // 2, self.shift_size // 2), mode=\"constant\")\n",
        "#         y = y.reshape(B, C, h * (w + 2 * (self.shift_size // 2)))\n",
        "#         y = y.permute(0, 2, 1)\n",
        "\n",
        "#         # Apply residual connection\n",
        "#         y = y + x\n",
        "\n",
        "#         return y\n",
        "\n",
        "# # Swin UNet Model\n",
        "# class SwinUNet(nn.Module):\n",
        "#     def __init__(self, input_channels, num_classes):\n",
        "#         super().__init__()\n",
        "\n",
        "#         # Swin Transformer Encoder Blocks\n",
        "#         self.enc1 = SwinTransformerEncoderBlock(embed_dim=64, num_heads=2, window_size=7, shift_size=0)\n",
        "#         self.enc2 = SwinTransformerEncoderBlock(embed_dim=128, num_heads=4, window_size=7, shift_size=0)\n",
        "#         self.enc3 = SwinTransformerEncoderBlock(embed_dim=256, num_heads=8, window_size=7, shift_size=0)\n",
        "#         self.enc4 = SwinTransformerEncoderBlock(embed_dim=512, num_heads=16, window_size=7, shift_size=0)\n",
        "\n",
        "#         # Swin Transformer Decoder Blocks\n",
        "#         self.dec1 = SwinTransformerEncoderBlock(embed_dim=256, num_heads=8, window_size=7, shift_size=0)\n",
        "#         self.dec2 = SwinTransformerEncoderBlock(embed_dim=128, num_heads=4, window_size=7, shift_size=0)\n",
        "#         self.dec3 = SwinTransformerEncoderBlock(embed_dim=64, num_heads=2, window_size=7, shift_size=0)\n",
        "\n",
        "#         # Final convolutional layer for segmentation output\n",
        "#         self.final_conv = nn.Conv2d(96, num_classes, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Encoder\n",
        "#         x1 = self.enc1(x)\n",
        "#         x2 = self.enc2(x1)\n",
        "#         x3 = self.enc3(x2)\n",
        "#         x4 = self.enc4(x3)\n",
        "\n",
        "#         # Decoder\n",
        "#         y1 = self.dec1(x4) + nn.functional.interpolate(x4, scale_factor=2, mode=\"nearest\")\n",
        "#         y2 = self.dec2(y1) + nn.functional.interpolate(y1, scale_factor=2, mode=\"nearest\")\n",
        "#         y3 = self.dec3(y2) + nn.functional.interpolate(y2, scale_factor=2, mode=\"nearest\")\n",
        "\n",
        "#         # Output\n",
        "#         y = self.final_conv(y3)\n",
        "#         return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIjhLRQpiPZQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# from torchvision.models.utils import load_state_dict_from_url\n",
        "\n",
        "# Swin Transformer Encoder Block\n",
        "class SwinTransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, window_size, shift_size, mlp_ratio=4.0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(embed_dim,(256, 256))\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim,(256, 256))\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(int(embed_dim * mlp_ratio), embed_dim),\n",
        "        )\n",
        "\n",
        "        # Window partitioning and shifting\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply layer normalization\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Apply self-attention\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        B, H, W, C = x.shape\n",
        "        x = x.reshape(B * H * W, C, 1)\n",
        "        x, _ = self.attn(x, x, x)\n",
        "        x = x.reshape(B, H, W, C)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Apply residual connection and layer normalization\n",
        "        x = x + x.permute(0, 2, 3, 1)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        # Apply MLP\n",
        "        y = self.mlp(x)\n",
        "\n",
        "        # Partition into non-overlapping windows and shift\n",
        "        B, N, C = y.shape\n",
        "        h = self.window_size\n",
        "        w = N // h\n",
        "        y = y.view(B, h, w, C)\n",
        "        y = y.permute(0, 3, 1, 2)\n",
        "        y = torch.nn.functional.pad(y, (0, 0, 0, 0, self.shift_size // 2, self.shift_size // 2), mode=\"constant\")\n",
        "        y = y.reshape(B, C, h * (w + 2 * (self.shift_size // 2)))\n",
        "        y = y.permute(0, 2, 1)\n",
        "\n",
        "        # Apply residual connection\n",
        "        y = y + x\n",
        "\n",
        "        return y\n",
        "\n",
        "# Swin UNet Model\n",
        "class SwinUNet(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Swin Transformer Encoder Blocks\n",
        "        self.enc1 = SwinTransformerEncoderBlock(embed_dim=64, num_heads=2, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.enc2 = SwinTransformerEncoderBlock(embed_dim=128, num_heads=4, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.enc3 = SwinTransformerEncoderBlock(embed_dim=256, num_heads=8, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.enc4 = SwinTransformerEncoderBlock(embed_dim=512, num_heads=16, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "\n",
        "        # Swin Transformer Decoder Blocks\n",
        "        self.dec1 = SwinTransformerEncoderBlock(embed_dim=256, num_heads=8, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.dec2 = SwinTransformerEncoderBlock(embed_dim=128, num_heads=4, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "        self.dec3 = SwinTransformerEncoderBlock(embed_dim=64, num_heads=2, window_size=7, shift_size=0,mlp_ratio=4.0)\n",
        "\n",
        "        # Final convolutional layer for segmentation output\n",
        "        self.final_conv = nn.Conv2d(96, num_classes, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        # Modify the input channel of the first convolutional layer\n",
        "        self.conv_input = nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.conv_input(x)\n",
        "        x1 = self.enc1(x)\n",
        "        x2 = self.enc2(x1)\n",
        "        x3 = self.enc3(x2)\n",
        "        x4 = self.enc4(x3)\n",
        "\n",
        "        # Decoder\n",
        "        y1 = self.dec1(x4) + nn.functional.interpolate(x4, scale_factor=2, mode=\"nearest\")\n",
        "        y2 = self.dec2(y1) + nn.functional.interpolate(y1, scale_factor=2, mode=\"nearest\")\n",
        "        y3 = self.dec3(y2) + nn.functional.interpolate(y2, scale_factor=2, mode=\"nearest\")\n",
        "\n",
        "        # Output\n",
        "        y = self.final_conv(y3)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chYBpoNxFQz1"
      },
      "source": [
        "##Config_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhkePFepFU5_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "class models_genesis_config:\n",
        "    model = \"Unet2D\"\n",
        "    suffix = \"genesis_chest_ct\"\n",
        "    exp_name = model + \"-\" + suffix\n",
        "    \n",
        "    # data\n",
        "    data = \"/mnt/dataset/shared/zongwei/LUNA16/Self_Learning_Cubes\" # not use\n",
        "    scale = 32\n",
        "    input_rows = 256\n",
        "    input_cols = 256\n",
        "    input_deps = 1\n",
        "    nb_class = 1\n",
        "\n",
        "    # image deformation\n",
        "    nonlinear_rate = 0.9\n",
        "    paint_rate = 0.9\n",
        "    outpaint_rate = 0.8\n",
        "    inpaint_rate = 1.0 - outpaint_rate\n",
        "    local_rate = 0.5\n",
        "    flip_rate = 0.4\n",
        "    \n",
        "    # logs\n",
        "    # model_dir = \"../SSLModel/Reuslts/pretrained_weights\"\n",
        "    model_dir = \"/content/drive/MyDrive/Spring_research_2023/SSLModel/Reuslts/pretrained_weights\"\n",
        "    timenow = datetime.strftime(datetime.now(pytz.timezone('Asia/Singapore')), '%Y-%m-%d_%H-%M-%S')\n",
        "    model_path = os.path.join(model_dir,timenow)\n",
        "    print('Model path: ',model_path)\n",
        "    if not os.path.exists(model_path):\n",
        "        os.makedirs(model_path)\n",
        "        \n",
        "    logs_path = os.path.join(model_path, \"Logs\")\n",
        "    print('log path: ',logs_path)\n",
        "    if not os.path.exists(logs_path):\n",
        "        os.makedirs(logs_path)\n",
        "        \n",
        "    shotdir = os.path.join(model_path, 'snapshot')\n",
        "    print('snapshot path: ',shotdir)\n",
        "    if not os.path.exists(shotdir):\n",
        "        os.makedirs(shotdir)\n",
        "    \n",
        "    # model pre-training\n",
        "    verbose = 1\n",
        "    weights = os.path.join(model_path,'ISIC_Unsup.pt')\n",
        "    batch_size = 1\n",
        "    optimizer = \"sgd\"\n",
        "    workers = 10\n",
        "    max_queue_size = workers * 4\n",
        "    save_samples = \"png\"\n",
        "    nb_epoch = 10000\n",
        "    patience = 100\n",
        "    lr = 0.01\n",
        "    \n",
        "    def display(self):\n",
        "        \"\"\"Display Configuration values.\"\"\"\n",
        "        print(\"\\nConfigurations:\")\n",
        "        for a in dir(self):\n",
        "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
        "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osDqssExFcnP"
      },
      "source": [
        "##Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ2VNWYaFfCN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import imgaug.augmenters as iaa\n",
        "#from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(1)\n",
        "\n",
        "\n",
        "def Dataset_Loader(path, img_size):\n",
        "    print('\\nLoading dataset...\\n')\n",
        "    read_imgs = np.load(path)\n",
        "    rows = img_size[0]\n",
        "    cols = img_size[1]\n",
        "    \n",
        "    images = np.ndarray((read_imgs.shape[0], read_imgs.shape[-1], rows, cols), dtype=float)\n",
        "    for i in range(read_imgs.shape[0]):\n",
        "        img = cv2.resize(read_imgs[i, 0], (cols, rows), interpolation=cv2.INTER_CUBIC)\n",
        "        images[i, 0, :, :] = img/255.\n",
        "    return images\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_path_train = '/content/drive/MyDrive/Spring_research_2023/data/GrayData'\n",
        "    trainpath = data_path_train + '/imgs_train.npy'\n",
        "    \n",
        "    dataset = Dataset_Loader(trainpath,[256,256])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xheYvE-oHI_1"
      },
      "source": [
        "#PART 2: Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7idZTJlWK8Y9"
      },
      "source": [
        "##Soft_dtw_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xOXtQ45K_X1"
      },
      "outputs": [],
      "source": [
        "# # Code by Maghoumi/pytorch-softdtw-cuda\n",
        "# # https://github.com/Maghoumi/pytorch-softdtw-cuda\n",
        "\n",
        "# # MIT License\n",
        "# #\n",
        "# # Copyright (c) 2020 Mehran Maghoumi\n",
        "# #\n",
        "# # Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# # of this software and associated documentation files (the \"Software\"), to deal\n",
        "# # in the Software without restriction, including without limitation the rights\n",
        "# # to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# # copies of the Software, and to permit persons to whom the Software is\n",
        "# # furnished to do so, subject to the following conditions:\n",
        "# #\n",
        "# # The above copyright notice and this permission notice shall be included in all\n",
        "# # copies or substantial portions of the Software.\n",
        "# #\n",
        "# # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "# # SOFTWARE.\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import torch.cuda\n",
        "# from numba import jit\n",
        "# from torch.autograd import Function\n",
        "# from numba import cuda\n",
        "# import math\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# @cuda.jit\n",
        "# def compute_softdtw_cuda(D, gamma, bandwidth, max_i, max_j, n_passes, R):\n",
        "#     \"\"\"\n",
        "#     :param seq_len: The length of the sequence (both inputs are assumed to be of the same size)\n",
        "#     :param n_passes: 2 * seq_len - 1 (The number of anti-diagonals)\n",
        "#     \"\"\"\n",
        "#     # Each block processes one pair of examples\n",
        "#     b = cuda.blockIdx.x\n",
        "#     # We have as many threads as seq_len, because the most number of threads we need\n",
        "#     # is equal to the number of elements on the largest anti-diagonal\n",
        "#     tid = cuda.threadIdx.x\n",
        "\n",
        "#     # Compute I, J, the indices from [0, seq_len)\n",
        "\n",
        "#     # The row index is always the same as tid\n",
        "#     I = tid\n",
        "\n",
        "#     inv_gamma = 1.0 / gamma\n",
        "\n",
        "#     # Go over each anti-diagonal. Only process threads that fall on the current on the anti-diagonal\n",
        "#     for p in range(n_passes):\n",
        "\n",
        "#         # The index is actually 'p - tid' but need to force it in-bounds\n",
        "#         J = max(0, min(p - tid, max_j - 1))\n",
        "\n",
        "#         # For simplicity, we define i, j which start from 1 (offset from I, J)\n",
        "#         i = I + 1\n",
        "#         j = J + 1\n",
        "\n",
        "#         # Only compute if element[i, j] is on the current anti-diagonal, and also is within bounds\n",
        "#         if I + J == p and (I < max_i and J < max_j):\n",
        "#             # Don't compute if outside bandwidth\n",
        "#             if not (abs(i - j) > bandwidth > 0):\n",
        "#                 r0 = -R[b, i - 1, j - 1] * inv_gamma\n",
        "#                 r1 = -R[b, i - 1, j] * inv_gamma\n",
        "#                 r2 = -R[b, i, j - 1] * inv_gamma\n",
        "#                 rmax = max(max(r0, r1), r2)\n",
        "#                 rsum = math.exp(r0 - rmax) + math.exp(r1 - rmax) + math.exp(r2 - rmax)\n",
        "#                 softmin = -gamma * (math.log(rsum) + rmax)\n",
        "#                 R[b, i, j] = D[b, i - 1, j - 1] + softmin\n",
        "\n",
        "#         # Wait for other threads in this block\n",
        "#         cuda.syncthreads()\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# @cuda.jit\n",
        "# def compute_softdtw_backward_cuda(D, R, inv_gamma, bandwidth, max_i, max_j, n_passes, E):\n",
        "#     k = cuda.blockIdx.x\n",
        "#     tid = cuda.threadIdx.x\n",
        "\n",
        "#     # Indexing logic is the same as above, however, the anti-diagonal needs to\n",
        "#     # progress backwards\n",
        "#     I = tid\n",
        "\n",
        "#     for p in range(n_passes):\n",
        "#         # Reverse the order to make the loop go backward\n",
        "#         rev_p = n_passes - p - 1\n",
        "\n",
        "#         # convert tid to I, J, then i, j\n",
        "#         J = max(0, min(rev_p - tid, max_j - 1))\n",
        "\n",
        "#         i = I + 1\n",
        "#         j = J + 1\n",
        "\n",
        "#         # Only compute if element[i, j] is on the current anti-diagonal, and also is within bounds\n",
        "#         if I + J == rev_p and (I < max_i and J < max_j):\n",
        "\n",
        "#             if math.isinf(R[k, i, j]):\n",
        "#                 R[k, i, j] = -math.inf\n",
        "\n",
        "#             # Don't compute if outside bandwidth\n",
        "#             if not (abs(i - j) > bandwidth > 0):\n",
        "#                 a = math.exp((R[k, i + 1, j] - R[k, i, j] - D[k, i + 1, j]) * inv_gamma)\n",
        "#                 b = math.exp((R[k, i, j + 1] - R[k, i, j] - D[k, i, j + 1]) * inv_gamma)\n",
        "#                 c = math.exp((R[k, i + 1, j + 1] - R[k, i, j] - D[k, i + 1, j + 1]) * inv_gamma)\n",
        "#                 E[k, i, j] = E[k, i + 1, j] * a + E[k, i, j + 1] * b + E[k, i + 1, j + 1] * c\n",
        "\n",
        "#         # Wait for other threads in this block\n",
        "#         cuda.syncthreads()\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# class _SoftDTWCUDA(Function):\n",
        "#     \"\"\"\n",
        "#     CUDA implementation is inspired by the diagonal one proposed in https://ieeexplore.ieee.org/document/8400444:\n",
        "#     \"Developing a pattern discovery method in time series data and its GPU acceleration\"\n",
        "#     \"\"\"\n",
        "\n",
        "#     @staticmethod\n",
        "#     def forward(ctx, D, gamma, bandwidth):\n",
        "#         dev = D.device\n",
        "#         dtype = D.dtype\n",
        "#         gamma = torch.cuda.FloatTensor([gamma])\n",
        "#         bandwidth = torch.cuda.FloatTensor([bandwidth])\n",
        "\n",
        "#         B = D.shape[0]\n",
        "#         N = D.shape[1]\n",
        "#         M = D.shape[2]\n",
        "#         threads_per_block = max(N, M)\n",
        "#         n_passes = 2 * threads_per_block - 1\n",
        "\n",
        "#         # Prepare the output array\n",
        "#         R = torch.ones((B, N + 2, M + 2), device=dev, dtype=dtype) * math.inf\n",
        "#         R[:, 0, 0] = 0\n",
        "\n",
        "#         # Run the CUDA kernel.\n",
        "#         # Set CUDA's grid size to be equal to the batch size (every CUDA block processes one sample pair)\n",
        "#         # Set the CUDA block size to be equal to the length of the longer sequence (equal to the size of the largest diagonal)\n",
        "#         compute_softdtw_cuda[B, threads_per_block](cuda.as_cuda_array(D.detach()),\n",
        "#                                                    gamma.item(), bandwidth.item(), N, M, n_passes,\n",
        "#                                                    cuda.as_cuda_array(R))\n",
        "#         ctx.save_for_backward(D, R, gamma, bandwidth)\n",
        "#         return R[:, -2, -2]\n",
        "\n",
        "#     @staticmethod\n",
        "#     def backward(ctx, grad_output):\n",
        "#         dev = grad_output.device\n",
        "#         dtype = grad_output.dtype\n",
        "#         D, R, gamma, bandwidth = ctx.saved_tensors\n",
        "\n",
        "#         B = D.shape[0]\n",
        "#         N = D.shape[1]\n",
        "#         M = D.shape[2]\n",
        "#         threads_per_block = max(N, M)\n",
        "#         n_passes = 2 * threads_per_block - 1\n",
        "\n",
        "#         D_ = torch.zeros((B, N + 2, M + 2), dtype=dtype, device=dev)\n",
        "#         D_[:, 1:N + 1, 1:M + 1] = D\n",
        "\n",
        "#         R[:, :, -1] = -math.inf\n",
        "#         R[:, -1, :] = -math.inf\n",
        "#         R[:, -1, -1] = R[:, -2, -2]\n",
        "\n",
        "#         E = torch.zeros((B, N + 2, M + 2), dtype=dtype, device=dev)\n",
        "#         E[:, -1, -1] = 1\n",
        "\n",
        "#         # Grid and block sizes are set same as done above for the forward() call\n",
        "#         compute_softdtw_backward_cuda[B, threads_per_block](cuda.as_cuda_array(D_),\n",
        "#                                                             cuda.as_cuda_array(R),\n",
        "#                                                             1.0 / gamma.item(), bandwidth.item(), N, M, n_passes,\n",
        "#                                                             cuda.as_cuda_array(E))\n",
        "#         E = E[:, 1:N + 1, 1:M + 1]\n",
        "#         return grad_output.view(-1, 1, 1).expand_as(E) * E, None, None\n",
        "\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# #\n",
        "# # The following is the CPU implementation based on https://github.com/Sleepwalking/pytorch-softdtw\n",
        "# # Credit goes to Kanru Hua.\n",
        "# # I've added support for batching and pruning.\n",
        "# #\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# @jit(nopython=True)\n",
        "# def compute_softdtw(D, gamma, bandwidth):\n",
        "#     B = D.shape[0]\n",
        "#     N = D.shape[1]\n",
        "#     M = D.shape[2]\n",
        "#     R = np.ones((B, N + 2, M + 2)) * np.inf\n",
        "#     R[:, 0, 0] = 0\n",
        "#     for b in range(B):\n",
        "#         for j in range(1, M + 1):\n",
        "#             for i in range(1, N + 1):\n",
        "\n",
        "#                 # Check the pruning condition\n",
        "#                 if 0 < bandwidth < np.abs(i - j):\n",
        "#                     continue\n",
        "\n",
        "#                 r0 = -R[b, i - 1, j - 1] / gamma\n",
        "#                 r1 = -R[b, i - 1, j] / gamma\n",
        "#                 r2 = -R[b, i, j - 1] / gamma\n",
        "#                 rmax = max(max(r0, r1), r2)\n",
        "#                 rsum = np.exp(r0 - rmax) + np.exp(r1 - rmax) + np.exp(r2 - rmax)\n",
        "#                 softmin = - gamma * (np.log(rsum) + rmax)\n",
        "#                 R[b, i, j] = D[b, i - 1, j - 1] + softmin\n",
        "#     return R\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# @jit(nopython=True)\n",
        "# def compute_softdtw_backward(D_, R, gamma, bandwidth):\n",
        "#     B = D_.shape[0]\n",
        "#     N = D_.shape[1]\n",
        "#     M = D_.shape[2]\n",
        "#     D = np.zeros((B, N + 2, M + 2))\n",
        "#     E = np.zeros((B, N + 2, M + 2))\n",
        "#     D[:, 1:N + 1, 1:M + 1] = D_\n",
        "#     E[:, -1, -1] = 1\n",
        "#     R[:, :, -1] = -np.inf\n",
        "#     R[:, -1, :] = -np.inf\n",
        "#     R[:, -1, -1] = R[:, -2, -2]\n",
        "#     for k in range(B):\n",
        "#         for j in range(M, 0, -1):\n",
        "#             for i in range(N, 0, -1):\n",
        "\n",
        "#                 if np.isinf(R[k, i, j]):\n",
        "#                     R[k, i, j] = -np.inf\n",
        "\n",
        "#                 # Check the pruning condition\n",
        "#                 if 0 < bandwidth < np.abs(i - j):\n",
        "#                     continue\n",
        "\n",
        "#                 a0 = (R[k, i + 1, j] - R[k, i, j] - D[k, i + 1, j]) / gamma\n",
        "#                 b0 = (R[k, i, j + 1] - R[k, i, j] - D[k, i, j + 1]) / gamma\n",
        "#                 c0 = (R[k, i + 1, j + 1] - R[k, i, j] - D[k, i + 1, j + 1]) / gamma\n",
        "#                 a = np.exp(a0)\n",
        "#                 b = np.exp(b0)\n",
        "#                 c = np.exp(c0)\n",
        "#                 E[k, i, j] = E[k, i + 1, j] * a + E[k, i, j + 1] * b + E[k, i + 1, j + 1] * c\n",
        "#     return E[:, 1:N + 1, 1:M + 1]\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# class _SoftDTW(Function):\n",
        "#     \"\"\"\n",
        "#     CPU implementation based on https://github.com/Sleepwalking/pytorch-softdtw\n",
        "#     \"\"\"\n",
        "\n",
        "#     @staticmethod\n",
        "#     def forward(ctx, D, gamma, bandwidth):\n",
        "#         dev = D.device\n",
        "#         dtype = D.dtype\n",
        "#         gamma = torch.Tensor([gamma]).to(dev).type(dtype)  # dtype fixed\n",
        "#         bandwidth = torch.Tensor([bandwidth]).to(dev).type(dtype)\n",
        "#         D_ = D.detach().cpu().numpy()\n",
        "#         g_ = gamma.item()\n",
        "#         b_ = bandwidth.item()\n",
        "#         R = torch.Tensor(compute_softdtw(D_, g_, b_)).to(dev).type(dtype)\n",
        "#         ctx.save_for_backward(D, R, gamma, bandwidth)\n",
        "#         return R[:, -2, -2]\n",
        "\n",
        "#     @staticmethod\n",
        "#     def backward(ctx, grad_output):\n",
        "#         dev = grad_output.device\n",
        "#         dtype = grad_output.dtype\n",
        "#         D, R, gamma, bandwidth = ctx.saved_tensors\n",
        "#         D_ = D.detach().cpu().numpy()\n",
        "#         R_ = R.detach().cpu().numpy()\n",
        "#         g_ = gamma.item()\n",
        "#         b_ = bandwidth.item()\n",
        "#         E = torch.Tensor(compute_softdtw_backward(D_, R_, g_, b_)).to(dev).type(dtype)\n",
        "#         return grad_output.view(-1, 1, 1).expand_as(E) * E, None, None\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# class SoftDTW(torch.nn.Module):\n",
        "#     \"\"\"\n",
        "#     The soft DTW implementation that optionally supports CUDA\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, use_cuda, gamma=1.0, normalize=False, bandwidth=None, dist_func=None):\n",
        "#         \"\"\"\n",
        "#         Initializes a new instance using the supplied parameters\n",
        "#         :param use_cuda: Flag indicating whether the CUDA implementation should be used\n",
        "#         :param gamma: sDTW's gamma parameter\n",
        "#         :param normalize: Flag indicating whether to perform normalization\n",
        "#                           (as discussed in https://github.com/mblondel/soft-dtw/issues/10#issuecomment-383564790)\n",
        "#         :param bandwidth: Sakoe-Chiba bandwidth for pruning. Passing 'None' will disable pruning.\n",
        "#         :param dist_func: Optional point-wise distance function to use. If 'None', then a default Euclidean distance function will be used.\n",
        "#         \"\"\"\n",
        "#         super(SoftDTW, self).__init__()\n",
        "#         self.normalize = normalize\n",
        "#         self.gamma = gamma\n",
        "#         self.bandwidth = 0 if bandwidth is None else float(bandwidth)\n",
        "#         self.use_cuda = use_cuda\n",
        "\n",
        "#         # Set the distance function\n",
        "#         if dist_func is not None:\n",
        "#             self.dist_func = dist_func\n",
        "#         else:\n",
        "#             self.dist_func = SoftDTW._euclidean_dist_func\n",
        "\n",
        "#     def _get_func_dtw(self, x, y):\n",
        "#         \"\"\"\n",
        "#         Checks the inputs and selects the proper implementation to use.\n",
        "#         \"\"\"\n",
        "#         bx, lx, dx = x.shape\n",
        "#         by, ly, dy = y.shape\n",
        "#         # Make sure the dimensions match\n",
        "#         assert bx == by  # Equal batch sizes\n",
        "#         assert dx == dy  # Equal feature dimensions\n",
        "\n",
        "#         use_cuda = self.use_cuda\n",
        "\n",
        "#         if use_cuda and (lx > 1024 or ly > 1024):  # We should be able to spawn enough threads in CUDA\n",
        "#                 print(\"SoftDTW: Cannot use CUDA because the sequence length > 1024 (the maximum block size supported by CUDA)\")\n",
        "#                 use_cuda = False\n",
        "\n",
        "#         # Finally, return the correct function\n",
        "#         return _SoftDTWCUDA.apply if use_cuda else _SoftDTW.apply\n",
        "\n",
        "#     @staticmethod\n",
        "#     def _euclidean_dist_func(x, y):\n",
        "#         \"\"\"\n",
        "#         Calculates the Euclidean distance between each element in x and y per timestep\n",
        "#         \"\"\"\n",
        "#         n = x.size(1)\n",
        "#         m = y.size(1)\n",
        "#         d = x.size(2)\n",
        "#         x = x.unsqueeze(2).expand(-1, n, m, d)\n",
        "#         y = y.unsqueeze(1).expand(-1, n, m, d)\n",
        "#         return torch.pow(x - y, 2).sum(3)\n",
        "\n",
        "#     def forward(self, X, Y):\n",
        "#         \"\"\"\n",
        "#         Compute the soft-DTW value between X and Y\n",
        "#         :param X: One batch of examples, batch_size x seq_len x dims\n",
        "#         :param Y: The other batch of examples, batch_size x seq_len x dims\n",
        "#         :return: The computed results\n",
        "#         \"\"\"\n",
        "\n",
        "#         # Check the inputs and get the correct implementation\n",
        "#         func_dtw = self._get_func_dtw(X, Y)\n",
        "\n",
        "#         if self.normalize:\n",
        "#             # Stack everything up and run\n",
        "#             x = torch.cat([X, X, Y])\n",
        "#             y = torch.cat([Y, X, Y])\n",
        "#             D = self.dist_func(x, y)\n",
        "#             out = func_dtw(D, self.gamma, self.bandwidth)\n",
        "#             out_xy, out_xx, out_yy = torch.split(out, X.shape[0])\n",
        "#             return out_xy - 1 / 2 * (out_xx + out_yy)\n",
        "#         else:\n",
        "#             D_xy = self.dist_func(X, Y)\n",
        "#             return func_dtw(D_xy, self.gamma, self.bandwidth)\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# def timed_run(a, b, sdtw):\n",
        "#     \"\"\"\n",
        "#     Runs a and b through sdtw, and times the forward and backward passes.\n",
        "#     Assumes that a requires gradients.\n",
        "#     :return: timing, forward result, backward result\n",
        "#     \"\"\"\n",
        "#     from timeit import default_timer as timer\n",
        "\n",
        "#     # Forward pass\n",
        "#     start = timer()\n",
        "#     forward = sdtw(a, b)\n",
        "#     end = timer()\n",
        "#     t = end - start\n",
        "\n",
        "#     grad_outputs = torch.ones_like(forward)\n",
        "\n",
        "#     # Backward\n",
        "#     start = timer()\n",
        "#     grads = torch.autograd.grad(forward, a, grad_outputs=grad_outputs)[0]\n",
        "#     end = timer()\n",
        "\n",
        "#     # Total time\n",
        "#     t += end - start\n",
        "\n",
        "#     return t, forward, grads\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# def profile(batch_size, seq_len_a, seq_len_b, dims, tol_backward):\n",
        "#     sdtw = SoftDTW(False, gamma=1.0, normalize=False)\n",
        "#     sdtw_cuda = SoftDTW(True, gamma=1.0, normalize=False)\n",
        "#     n_iters = 6\n",
        "\n",
        "#     print(\"Profiling forward() + backward() times for batch_size={}, seq_len_a={}, seq_len_b={}, dims={}...\".format(batch_size, seq_len_a, seq_len_b, dims))\n",
        "\n",
        "#     times_cpu = []\n",
        "#     times_gpu = []\n",
        "\n",
        "#     for i in range(n_iters):\n",
        "#         a_cpu = torch.rand((batch_size, seq_len_a, dims), requires_grad=True)\n",
        "#         b_cpu = torch.rand((batch_size, seq_len_b, dims))\n",
        "#         a_gpu = a_cpu.cuda()\n",
        "#         b_gpu = b_cpu.cuda()\n",
        "\n",
        "#         # GPU\n",
        "#         t_gpu, forward_gpu, backward_gpu = timed_run(a_gpu, b_gpu, sdtw_cuda)\n",
        "\n",
        "#         # CPU\n",
        "#         t_cpu, forward_cpu, backward_cpu = timed_run(a_cpu, b_cpu, sdtw)\n",
        "\n",
        "#         # Verify the results\n",
        "#         assert torch.allclose(forward_cpu, forward_gpu.cpu())\n",
        "#         assert torch.allclose(backward_cpu, backward_gpu.cpu(), atol=tol_backward)\n",
        "\n",
        "#         if i > 0:  # Ignore the first time we run, in case this is a cold start (because timings are off at a cold start of the script)\n",
        "#             times_cpu += [t_cpu]\n",
        "#             times_gpu += [t_gpu]\n",
        "\n",
        "#     # Average and log\n",
        "#     avg_cpu = np.mean(times_cpu)\n",
        "#     avg_gpu = np.mean(times_gpu)\n",
        "#     print(\"\\tCPU:     \", avg_cpu)\n",
        "#     print(\"\\tGPU:     \", avg_gpu)\n",
        "#     print(\"\\tSpeedup: \", avg_cpu / avg_gpu)\n",
        "#     print()\n",
        "\n",
        "# # ----------------------------------------------------------------------------------------------------------------------\n",
        "# if __name__ == \"__main__\":\n",
        "#     from timeit import default_timer as timer\n",
        "\n",
        "#     torch.manual_seed(1234)\n",
        "\n",
        "#     profile(128, 17, 15, 2, tol_backward=1e-6)\n",
        "#     profile(512, 64, 64, 2, tol_backward=1e-4)\n",
        "#     profile(512, 256, 256, 2, tol_backward=1e-3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOH5KSMuIOh1"
      },
      "source": [
        "##Kmeans func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdD2F-dcIR39"
      },
      "outputs": [],
      "source": [
        "# from functools import partial\n",
        "\n",
        "# import os\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # from soft_dtw_cuda import SoftDTW\n",
        "\n",
        "\n",
        "# def initialize(X, num_clusters):\n",
        "#     \"\"\"\n",
        "#     initialize cluster centers\n",
        "#     :param X: (torch.tensor) matrix\n",
        "#     :param num_clusters: (int) number of clusters\n",
        "#     :return: (np.array) initial state\n",
        "#     \"\"\"\n",
        "#     num_samples = len(X)\n",
        "#     indices = np.random.choice(num_samples, num_clusters, replace=False)\n",
        "#     initial_state = X[indices]\n",
        "#     return initial_state\n",
        "\n",
        "\n",
        "# def kmeans(\n",
        "#         X,\n",
        "#         num_clusters,\n",
        "#         distance='euclidean',\n",
        "#         cluster_centers=[],\n",
        "#         tol=1e-4,\n",
        "#         tqdm_flag=True,\n",
        "#         iter_limit=0,\n",
        "#         device=torch.device('cpu'),\n",
        "#         gamma_for_soft_dtw=0.001\n",
        "# ):\n",
        "#     \"\"\"\n",
        "#     perform kmeans\n",
        "#     :param X: (torch.tensor) matrix\n",
        "#     :param num_clusters: (int) number of clusters\n",
        "#     :param distance: (str) distance [options: 'euclidean', 'cosine'] [default: 'euclidean']\n",
        "#     :param tol: (float) threshold [default: 0.0001]\n",
        "#     :param device: (torch.device) device [default: cpu]\n",
        "#     :param tqdm_flag: Allows to turn logs on and off\n",
        "#     :param iter_limit: hard limit for max number of iterations\n",
        "#     :param gamma_for_soft_dtw: approaches to (hard) DTW as gamma -> 0\n",
        "#     :return: (torch.tensor, torch.tensor) cluster ids, cluster centers\n",
        "#     \"\"\"\n",
        "#     if tqdm_flag:\n",
        "#         print(f'running k-means on {device}..')\n",
        "\n",
        "#     if distance == 'euclidean':\n",
        "#         pairwise_distance_function = partial(pairwise_distance, device=device, tqdm_flag=tqdm_flag)\n",
        "#     elif distance == 'cosine':\n",
        "#         pairwise_distance_function = partial(pairwise_cosine, device=device)\n",
        "#     elif distance == 'soft_dtw':\n",
        "#         sdtw = SoftDTW(use_cuda=device.type == 'cuda', gamma=gamma_for_soft_dtw)\n",
        "#         pairwise_distance_function = partial(pairwise_soft_dtw, sdtw=sdtw, device=device)\n",
        "#     else:\n",
        "#         raise NotImplementedError\n",
        "\n",
        "#     # convert to float\n",
        "#     X = X.float()\n",
        "\n",
        "#     # transfer to device\n",
        "#     X = X.to(device)\n",
        "\n",
        "#     # initialize\n",
        "#     if type(cluster_centers) == list:  # ToDo: make this less annoyingly weird\n",
        "#         initial_state = initialize(X, num_clusters)\n",
        "#     else:\n",
        "#         if tqdm_flag:\n",
        "#             print('resuming')\n",
        "#         # find data point closest to the initial cluster center\n",
        "#         initial_state = cluster_centers\n",
        "#         dis = pairwise_distance_function(X, initial_state)\n",
        "#         choice_points = torch.argmin(dis, dim=0)\n",
        "#         initial_state = X[choice_points]\n",
        "#         initial_state = initial_state.to(device)\n",
        "\n",
        "#     iteration = 0\n",
        "#     if tqdm_flag:\n",
        "#         tqdm_meter = tqdm(desc='[running kmeans]')\n",
        "#     while True:\n",
        "\n",
        "#         dis = pairwise_distance_function(X, initial_state)\n",
        "\n",
        "#         choice_cluster = torch.argmin(dis, dim=1)\n",
        "\n",
        "#         initial_state_pre = initial_state.clone()\n",
        "\n",
        "#         for index in range(num_clusters):\n",
        "#             selected = torch.nonzero(choice_cluster == index).squeeze().to(device)\n",
        "\n",
        "#             selected = torch.index_select(X, 0, selected)\n",
        "\n",
        "#             # https://github.com/subhadarship/kmeans_pytorch/issues/16\n",
        "#             if selected.shape[0] == 0:\n",
        "#                 selected = X[torch.randint(len(X), (1,))]\n",
        "\n",
        "#             initial_state[index] = selected.mean(dim=0)\n",
        "\n",
        "#         center_shift = torch.sum(\n",
        "#             torch.sqrt(\n",
        "#                 torch.sum((initial_state - initial_state_pre) ** 2, dim=1)\n",
        "#             ))\n",
        "\n",
        "#         # increment iteration\n",
        "#         iteration = iteration + 1\n",
        "\n",
        "#         # update tqdm meter\n",
        "#         if tqdm_flag:\n",
        "#             tqdm_meter.set_postfix(\n",
        "#                 iteration=f'{iteration}',\n",
        "#                 center_shift=f'{center_shift ** 2:0.6f}',\n",
        "#                 tol=f'{tol:0.6f}'\n",
        "#             )\n",
        "#             tqdm_meter.update()\n",
        "#         if center_shift ** 2 < tol:\n",
        "#             break\n",
        "#         if iter_limit != 0 and iteration >= iter_limit:\n",
        "#             break\n",
        "\n",
        "#     return choice_cluster.cpu(), initial_state.cpu()\n",
        "\n",
        "\n",
        "# def kmeans_predict(\n",
        "#         X,\n",
        "#         cluster_centers,\n",
        "#         distance='euclidean',\n",
        "#         device=torch.device('cpu'),\n",
        "#         gamma_for_soft_dtw=0.001,\n",
        "#         tqdm_flag=True\n",
        "# ):\n",
        "#     \"\"\"\n",
        "#     predict using cluster centers\n",
        "#     :param X: (torch.tensor) matrix\n",
        "#     :param cluster_centers: (torch.tensor) cluster centers\n",
        "#     :param distance: (str) distance [options: 'euclidean', 'cosine'] [default: 'euclidean']\n",
        "#     :param device: (torch.device) device [default: 'cpu']\n",
        "#     :param gamma_for_soft_dtw: approaches to (hard) DTW as gamma -> 0\n",
        "#     :return: (torch.tensor) cluster ids\n",
        "#     \"\"\"\n",
        "#     if tqdm_flag:\n",
        "#         print(f'predicting on {device}..')\n",
        "\n",
        "#     if distance == 'euclidean':\n",
        "#         pairwise_distance_function = partial(pairwise_distance, device=device, tqdm_flag=tqdm_flag)\n",
        "#     elif distance == 'cosine':\n",
        "#         pairwise_distance_function = partial(pairwise_cosine, device=device)\n",
        "#     elif distance == 'soft_dtw':\n",
        "#         sdtw = SoftDTW(use_cuda=device.type == 'cuda', gamma=gamma_for_soft_dtw)\n",
        "#         pairwise_distance_function = partial(pairwise_soft_dtw, sdtw=sdtw, device=device)\n",
        "#     else:\n",
        "#         raise NotImplementedError\n",
        "\n",
        "#     # convert to float\n",
        "#     X = X.float()\n",
        "\n",
        "#     # transfer to device\n",
        "#     X = X.to(device)\n",
        "\n",
        "#     dis = pairwise_distance_function(X, cluster_centers)\n",
        "#     choice_cluster = torch.argmin(dis, dim=1)\n",
        "\n",
        "#     #return choice_cluster.cpu()\n",
        "#     return dis\n",
        "\n",
        "\n",
        "# def pairwise_distance(data1, data2, device=torch.device('cpu'), tqdm_flag=True):\n",
        "#     if tqdm_flag:\n",
        "#         print(f'device is :{device}')\n",
        "    \n",
        "#     # transfer to device\n",
        "#     data1, data2 = data1.to(device), data2.to(device)\n",
        "\n",
        "#     # N*1*M\n",
        "#     A = data1.unsqueeze(dim=1)\n",
        "\n",
        "#     # 1*N*M\n",
        "#     B = data2.unsqueeze(dim=0)\n",
        "\n",
        "#     dis = (A - B) ** 2.0\n",
        "#     # return N*N matrix for pairwise distance\n",
        "#     dis = dis.sum(dim=-1).squeeze()\n",
        "#     return dis\n",
        "\n",
        "\n",
        "# def pairwise_cosine(data1, data2, device=torch.device('cpu')):\n",
        "#     # transfer to device\n",
        "#     data1, data2 = data1.to(device), data2.to(device)\n",
        "\n",
        "#     # N*1*M\n",
        "#     A = data1.unsqueeze(dim=1)\n",
        "\n",
        "#     # 1*N*M\n",
        "#     B = data2.unsqueeze(dim=0)\n",
        "\n",
        "#     # normalize the points  | [0.3, 0.4] -> [0.3/sqrt(0.09 + 0.16), 0.4/sqrt(0.09 + 0.16)] = [0.3/0.5, 0.4/0.5]\n",
        "#     A_normalized = A / A.norm(dim=-1, keepdim=True)\n",
        "#     B_normalized = B / B.norm(dim=-1, keepdim=True)\n",
        "\n",
        "#     cosine = A_normalized * B_normalized\n",
        "\n",
        "#     # return N*N matrix for pairwise distance\n",
        "#     cosine_dis = 1 - cosine.sum(dim=-1).squeeze()\n",
        "#     return cosine_dis\n",
        "\n",
        "\n",
        "# def pairwise_soft_dtw(data1, data2, sdtw=None, device=torch.device('cpu')):\n",
        "#     if sdtw is None:\n",
        "#         raise ValueError('sdtw is None - initialize it with SoftDTW')\n",
        "\n",
        "#     # transfer to device\n",
        "#     data1, data2 = data1.to(device), data2.to(device)\n",
        "\n",
        "#     # (batch_size, seq_len, feature_dim=1)\n",
        "#     A = data1.unsqueeze(dim=2)\n",
        "\n",
        "#     # (cluster_size, seq_len, feature_dim=1)\n",
        "#     B = data2.unsqueeze(dim=2)\n",
        "\n",
        "#     distances = []\n",
        "#     for b in B:\n",
        "#         # (1, seq_len, 1)\n",
        "#         b = b.unsqueeze(dim=0)\n",
        "#         A, b = torch.broadcast_tensors(A, b)\n",
        "#         # (batch_size, 1)\n",
        "#         sdtw_distance = sdtw(b, A).view(-1, 1)\n",
        "#         distances.append(sdtw_distance)\n",
        "\n",
        "#     # (batch_size, cluster_size)\n",
        "#     dis = torch.cat(distances, dim=1)\n",
        "#     return dis\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "    \n",
        "#     print(\"torch = {}\".format(torch.__version__))\n",
        "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "#     device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "#     feature_path = '/ceph-jd/pub/jupyter/zhaozy/notebooks/LWJ/UnsupModel/Reuslts/pretrained_weights/2022-01-01_02-09-51/feature_map.npy' \n",
        "#     save_path = '/ceph-jd/pub/jupyter/zhaozy/notebooks/LWJ/UnsupModel/Reuslts/'\n",
        "#     matrix = 'euclidean'\n",
        "    \n",
        "#     feature_map = np.load(feature_path)\n",
        "#     map1=torch.from_numpy(feature_map)\n",
        "#     map2 = torch.flatten(map1, start_dim=1, end_dim=-1)\n",
        "#     cluster_ids_x, cluster_centers = kmeans(\n",
        "#         X=map2, num_clusters=3, distance=matrix, device=device)\n",
        "    \n",
        "    \n",
        "   \n",
        "#     print('save at:')\n",
        "#     print('cluster_ids_x :',os.path.join(save_path,matrix + '_cluster_ids_x.pt'))\n",
        "#     print('cluster_centers: ', os.path.join(save_path,matrix + '_cluster_centers.pt'))\n",
        "    \n",
        "#     torch.save(cluster_ids_x,os.path.join(save_path,matrix + '_cluster_ids_x.pt'))\n",
        "#     torch.save(cluster_centers,os.path.join(save_path,matrix + '_cluster_centers.pt'))\n",
        "    \n",
        "#     cluster_dis = kmeans_predict(map2, cluster_centers, matrix, device=device)\n",
        "    \n",
        "#     torch.save(cluster_dis,os.path.join(save_path,matrix + '_cluster_centers_dis.pt'))\n",
        "    \n",
        "    \n",
        "#     cluster_map = []\n",
        "#     for i in range(3):\n",
        "#         dis, idx_sort = torch.sort(cluster_dis[:,i], dim=0, descending=False)\n",
        "#         cluster_map.append({'dis':dis,'idx_sort':idx_sort})\n",
        "            \n",
        "#     np.save(os.path.join(save_path,matrix + '_cluster.npy'),cluster_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euRbhKC2IB2l"
      },
      "source": [
        "##Config_cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U2UOPhrHLV_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "class models_genesis_config:\n",
        "    model = \"Unet2D\"\n",
        "    suffix = \"genesis_chest_ct\"\n",
        "    exp_name = model + \"-\" + suffix\n",
        "    \n",
        "    # data\n",
        "    data = \"/mnt/dataset/shared/zongwei/LUNA16/Self_Learning_Cubes\" # not use\n",
        "    scale = 32\n",
        "    input_rows = 256\n",
        "    input_cols = 256\n",
        "    input_deps = 1\n",
        "    nb_class = 1\n",
        "\n",
        "    # image deformation\n",
        "    nonlinear_rate = 0.9\n",
        "    paint_rate = 0.9\n",
        "    outpaint_rate = 0.8\n",
        "    inpaint_rate = 1.0 - outpaint_rate\n",
        "    local_rate = 0.5\n",
        "    flip_rate = 0.4\n",
        "    \n",
        "    # logs\n",
        "    model_dir = \"/content/drive/MyDrive/Spring_research_2023/SSLModel/Reuslts/pretrained_weights\"\n",
        "    timenow = datetime.strftime(datetime.now(pytz.timezone('Asia/Singapore')), '%Y-%m-%d_%H-%M-%S')\n",
        "    model_path = os.path.join(model_dir,timenow)\n",
        "    print('Model path: ',model_path)\n",
        "    if not os.path.exists(model_path):\n",
        "        os.makedirs(model_path)\n",
        "        \n",
        "    logs_path = os.path.join(model_path, \"Logs\")\n",
        "    print('log path: ',logs_path)\n",
        "    if not os.path.exists(logs_path):\n",
        "        os.makedirs(logs_path)\n",
        "        \n",
        "    shotdir = os.path.join(model_path, 'snapshot')\n",
        "    print('snapshot path: ',shotdir)\n",
        "    if not os.path.exists(shotdir):\n",
        "        os.makedirs(shotdir)\n",
        "    \n",
        "    # model pre-training\n",
        "    verbose = 1\n",
        "    weights = os.path.join(model_path,'ISIC_Unsup.pt')\n",
        "    batch_size = 1\n",
        "    optimizer = \"sgd\"\n",
        "    workers = 10\n",
        "    max_queue_size = workers * 4\n",
        "    save_samples = \"png\"\n",
        "    nb_epoch = 100\n",
        "    patience = 50\n",
        "    lr = 0.01\n",
        "    \n",
        "    def display(self):\n",
        "        \"\"\"Display Configuration values.\"\"\"\n",
        "        print(\"\\nConfigurations:\")\n",
        "        for a in dir(self):\n",
        "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
        "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1hgaun7H6nF"
      },
      "source": [
        "##Cluster "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTkn9-r3H8D3"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import sys\n",
        "# from utils import *\n",
        "# import unet3d\n",
        "# from unet_model2 import UNet, UNet_hidden\n",
        "# from config_cluster import models_genesis_config\n",
        "from tqdm import tqdm\n",
        "# from data_load import Dataset_Loader\n",
        "from datetime import datetime\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# from kmeans_func import kmeans, kmeans_predict\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# =================================================\n",
        "#             load data and model\n",
        "# =================================================\n",
        "\n",
        "print(\"torch = {}\".format(torch.__version__))\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Total CUDA devices: \", torch.cuda.device_count())\n",
        "img_size = [256,256]\n",
        "input_rows, input_cols = 256, 256\n",
        "conf = models_genesis_config()\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Spring_research_2023/data/GrayData/imgs_train.npy'\n",
        "train_set = Dataset_Loader(train_path,img_size)\n",
        "\n",
        "train_num =  1600\n",
        "x_train = train_set[0:train_num]\n",
        "print(\"x_train: {} | {:.2f} ~ {:.2f}\".format(x_train.shape, np.min(x_train), np.max(x_train)))\n",
        "training_generator = generate_pair(x_train,conf.batch_size, conf)\n",
        "\n",
        "model = UNet_hidden(n_channels=1, n_classes=conf.nb_class).cpu()\n",
        "model.to(device)\n",
        "summary(model, (1,input_rows,input_cols), batch_size=-1)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# =================================================\n",
        "#             extract hidden features\n",
        "# =================================================\n",
        "conf.weights = '/content/drive/MyDrive/Spring_research_2023/SSLModel/Reuslts/pretrained_weights/2023-04-02_02-19-33/ISIC_Unsup.pt'\n",
        "\n",
        "if conf.weights != None:\n",
        "    checkpoint=torch.load(conf.weights)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    print(\"Loading weights from \",conf.weights)\n",
        "sys.stdout.flush()\n",
        "\n",
        "feature_map = []\n",
        "for iteration in tqdm(range(int(x_train.shape[0]//conf.batch_size))):\n",
        "    image, _ = next(training_generator)\n",
        "    image = torch.from_numpy(image).float().to(device)\n",
        "    _, feature=model(image)\n",
        "    descriptors = feature.cpu().detach().numpy()\n",
        "    for i in range(conf.batch_size):\n",
        "        feature_map.append(descriptors[i])\n",
        "print('\\nsize of feature_map:',np.shape(feature_map))\n",
        "np.save(os.path.join(conf.model_path,'2023-04-02_02-19-33_feature_map.npy'),feature_map)\n",
        "print('path of feature map:',os.path.join(conf.model_path,'2023-04-02_02-19-33_feature_map.npy'))\n",
        "'''\n",
        "feature_path = '../SSLModel/Reuslts/pretrained_weights/2022-01-13_04-14-30/feature_map.npy'\n",
        "feature_map = np.load(feature_path)\n",
        "'''\n",
        "newmap=torch.from_numpy(np.array(feature_map))\n",
        "\n",
        "# =================================================\n",
        "#           dimensionality reduction\n",
        "# =================================================\n",
        "class PCA(object):\n",
        "    def __init__(self, n_components=2):\n",
        "        self.n_components = n_components\n",
        "\n",
        "    def fit(self, X):\n",
        "        n = X.shape[0]\n",
        "        self.mean = torch.mean(X, axis=0)\n",
        "        X = X - self.mean\n",
        "        covariance_matrix = 1 / n * torch.matmul(X.T, X)\n",
        "        eigenvalues, eigenvectors = torch.eig(covariance_matrix, eigenvectors=True)\n",
        "        eigenvalues = torch.norm(eigenvalues, dim=1)\n",
        "        idx = torch.argsort(-eigenvalues)\n",
        "        eigenvectors = eigenvectors[:, idx]\n",
        "        self.proj_mat = eigenvectors[:, 0:self.n_components]\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X - self.mean\n",
        "        return X.matmul(self.proj_mat)\n",
        "\n",
        "print('========== processing dimensionality reduction ===========')\n",
        "redim_type = 'pooling_512'\n",
        "dim = 512\n",
        "if redim_type == 'flatten_PCA':  # in paper, no use PCA\n",
        "    # flatten\n",
        "    flatten_map = torch.flatten(newmap, start_dim=1, end_dim=-1)\n",
        "    # pca\n",
        "    pca = PCA(n_components=np.shape(flatten_map)[1])\n",
        "    pca.fit(flatten_map)\n",
        "    X_all = pca.transform(flatten_map)\n",
        "    reduced = X_all[:,0:dim]\n",
        "    \n",
        "elif redim_type == 'pooling_512':\n",
        "    # adaptive average pool\n",
        "    aap512 = nn.AdaptiveAvgPool2d((1))\n",
        "    map_aap512 = aap512(newmap)\n",
        "    reduced =  torch.flatten(map_aap512, start_dim=1, end_dim=-1)\n",
        "    \n",
        "elif redim_type == 'pooling_2048':\n",
        "    aap2048 = nn.AdaptiveAvgPool2d((2,2))\n",
        "    map_aap2048 = aap2048(newmap)\n",
        "    reduced = torch.flatten(map_aap2048, start_dim=1, end_dim=-1)\n",
        "    \n",
        "print(redim_type)\n",
        "print('\\nfeature shape:', np.shape(reduced))\n",
        "\n",
        "# =================================================\n",
        "#                     clustering\n",
        "# =================================================\n",
        "dir_path = '/content/drive/MyDrive/Spring_research_2023/Cluster_Results/Hidden_features' # save path of features\n",
        "matrix = 'euclidean'\n",
        "num_clusters = 10\n",
        "\n",
        "# dim_list = [512,256,128,64]\n",
        "dim_list = 512\n",
        "for dim in range(dim_list):\n",
        "    # reduced = X_all[:,0:dim]\n",
        "    x = reduced\n",
        "    \n",
        "    name = matrix+'_'+redim_type+'_dim'+str(dim)\n",
        "    save_path = os.path.join(dir_path,name)\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    print('/nFeatures save under: ',save_path)\n",
        "\n",
        "    timenow = datetime.strftime(datetime.now(pytz.timezone('Asia/Singapore')),'%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "\n",
        "    cluster_ids_x, cluster_centers = kmeans(\n",
        "        X=x, num_clusters=num_clusters, distance=matrix, device=device\n",
        "    )\n",
        "    cluster_dis = kmeans_predict(x, cluster_centers, matrix, device=device)\n",
        "\n",
        "    print('\\nsave at:')\n",
        "    print('cluster_ids_x :',os.path.join(save_path,timenow + '_cluster_ids_x.pt'))\n",
        "    print('cluster_centers: ', os.path.join(save_path,timenow + '_cluster_centers.pt'))\n",
        "    print('cluster_distances: ', os.path.join(save_path,timenow + '_cluster_centers_dis.pt'))\n",
        "\n",
        "    torch.save(cluster_ids_x,os.path.join(save_path,timenow + '_cluster_ids_x.pt'))\n",
        "    torch.save(cluster_centers,os.path.join(save_path,timenow + '_cluster_centers.pt'))    \n",
        "    torch.save(cluster_dis,os.path.join(save_path,timenow + '_cluster_centers_dis.pt'))\n",
        "\n",
        "    cluster_map = []\n",
        "    for i in range(num_clusters):\n",
        "        dis, idx_sort = torch.sort(cluster_dis[:,i], dim=0, descending=False)\n",
        "        cluster_map.append({'dis':dis,'idx_sort':idx_sort})\n",
        "\n",
        "    print('cluster_distance rank: ', os.path.join(save_path,timenow + '_cluster.npy'))\n",
        "    np.save(os.path.join(save_path,timenow + '_cluster.npy'),cluster_map)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}